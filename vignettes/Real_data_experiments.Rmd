---
title: "Real_data_experiments"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Real_data_experiments}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

# Set up

```{r setup, include = FALSE}
devtools::load_all()
library(DS23IRLS)
library(msme)
library(dplyr)
library(ggplot2)
library(reshape2)
library(patchwork)
library(splitTools)
library(MASS)
library(class)
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = '#>'
)
```

# Data sets

All three data sets come from the UCI Repository and are widely known in the ML community. For more details we advise to read the documentation under `?raisin` for raisin dataset. These data sets don't contain any missing, or categorical values, so only preprocessing needed is the removal of co-linear features, which will be detected via Pearson's Correlation.

```{r data sets}
data('raisin')
data('occupancy')
data('banknote')
knitr::kable(head(raisin))
knitr::kable(head(occupancy))
knitr::kable(head(banknote))
```

## Removing co-linear variables

To ensure obtaining the high quality results we decide to remove co-linear variables, which are the variables having high Pearson's correlation value (over 0.7).

```{r fig.width = 8, fig.height = 10, warning=FALSE}
cor_raisin    <- melt(round(cor(select(raisin, Area, MajorAxisLength, 
                                       MinorAxisLength, Eccentricity, 
                                       ConvexArea, Extent, Perimeter)), 2))
cor_occupancy <- melt(round(cor(select(occupancy, Temperature, Humidity, 
                                       Light, CO2, HumidityRatio)), 2))
cor_banknote  <- melt(round(cor(select(banknote, X1, X2, X3, X4)), 2))

plot_heatmaps(cor_raisin, cor_occupancy, cor_banknote)
```

As we can see, Raisin dataset has the abundance of highly correlated features, and we delete all of them. Finally we end up with the data sets described by 3 or 4 features.

```{r fig.width = 8, fig.height = 10, warning = FALSE}
raisin    <- raisin[, -c(1, 2, 3, 5)]
occupancy <- occupancy[, -5]
banknote  <- banknote[, -3]

cor_raisin    <- melt(round(cor(select(raisin, Eccentricity, 
                                       Extent, Perimeter)), 2))
cor_occupancy <- melt(round(cor(select(occupancy, Temperature, Humidity, 
                                       Light, CO2)), 2))
cor_banknote  <- melt(round(cor(select(banknote, X1, X2, X4)), 2))

plot_heatmaps(cor_raisin, cor_occupancy, cor_banknote)
```

After removing the highly correlated values (r rank > 0.7) we've greatly diminished a Raisin dataset to just three out of seven variables, the occupancy dataset remained as it was, whereas from the banknote we removed X3 feature.

## Train test split

We prepare a train test split from our function which is a wrapper for the split function from `SplitTools`. Additionally we limit the number of observations for the occupancy data set to 2000, as training on all observations is computationally costly.

```{r}
occupancy       <- occupancy[1:2000, ]
raisin_split    <- train_test_split(raisin, p = c(0.8, 0.2))
occupancy_split <- train_test_split(occupancy, p = c(0.8, 0.2))
banknote_split  <- train_test_split(banknote, p = c(0.8, 0.2))
```

# Experiments

## Singular run

During the first experiment we conduct a singular run of every model and compare the outcomes in form of the table.

### Raisin

```{r}
train <- raisin_split$train
test  <- raisin_split$test

comp_raisin <- compare_models(train, test, interactions = data.frame(a = c('Perimeter'), b = c('Extent')))
knitr::kable(comp_raisin)
```

### Occupancy

```{r}
train <- occupancy_split$train
test  <- occupancy_split$test

comp_occupancy <- compare_models(train, test, interactions = data.frame(a = c('Light'), b = c('Temperature')))
knitr::kable(comp_occupancy)
```

### Banknote

```{r}
train <- banknote_split$train
test  <- banknote_split$test

comp_banknote <- compare_models(train, test, interactions = data.frame(a = c('X4'), b = c('X2')))
knitr::kable(comp_banknote)
```




## Multiple runs

During the second experiment we conduct 5 runs on different split sizes (0.9, 0.8, 0.7, 0.6, 0.5) of every model and compare the outcomes in form of the boxplot.

### Raisin

```{r fig.width = 8, fig.height = 10, warning = FALSE}
multiple_eval <- multiple_exp(include_occupancy = TRUE)
boxplots(multiple_eval$out_raisin)
```

As we can see, KNN, QDA, and LDA algorithms perform poorly in terms of accuracy, which makes us ignore other results, such as perfect recall for the KNN. Other methods are comparable, however our IRLS with interaction is always a bit better.

### Occupancy

```{r fig.width = 8, fig.height = 10, warning=FALSE}
boxplots(multiple_eval$out_occupancy)
```

As we can see, KNN, QDA, and LDA algorithms perform poorly in terms of accuracy, which makes us ignore other results, such as perfect recall for the KNN. Other methods are comparable, however our IRLS with interaction is always a bit better.

### Banknote

```{r fig.width = 8, fig.height = 10, warning=FALSE}
boxplots(multiple_eval$out_banknote)
```

This time, our conclusions are similar, however we can clearly see that our irls with interactions is significantly better than other methods.

